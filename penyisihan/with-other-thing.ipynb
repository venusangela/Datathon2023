{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":58509,"databundleVersionId":6321744,"sourceType":"competition"},{"sourceId":6278548,"sourceType":"datasetVersion","datasetId":3609769}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-10T16:20:38.714331Z","iopub.execute_input":"2023-08-10T16:20:38.714666Z","iopub.status.idle":"2023-08-10T16:20:38.755837Z","shell.execute_reply.started":"2023-08-10T16:20:38.714636Z","shell.execute_reply":"2023-08-10T16:20:38.754922Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/ristek-datathon-2023/sample_submission.csv\n/kaggle/input/ristek-datathon-2023/train.csv\n/kaggle/input/ristek-datathon-2023/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import pandas as pd    # digunakan untuk manipulasi dan analisis data\nimport matplotlib.pyplot as plt   # digunakan untuk visualisasi data\nimport seaborn as sns   # juga digunakan untuk visualisasi data\nfrom sklearn.preprocessing import StandardScaler  # digunakan untuk standardisasi fitur dengan menghapus mean dan menskalakan ke variance unit\nimport plotly.express as px   # digunakan untuk visualisasi interaktif\nimport numpy as np    # digunakan untuk komputasi numerik\nfrom plotly.subplots import make_subplots   # digunakan untuk membangun plot subplots plotly\nimport plotly.graph_objects as go   # digunakan untuk membangun plot plotly\nfrom sklearn.impute import SimpleImputer   # digunakan untuk pengisian data yang hilang\nfrom sklearn.compose import ColumnTransformer   # digunakan untuk menggabungkan beberapa transformers dalam satu alur\nfrom sklearn.preprocessing import OneHotEncoder   # digunakan untuk enkoding variabel kategorikal\nfrom sklearn.model_selection import train_test_split   # digunakan untuk membagi data menjadi train dan test\nfrom sklearn.metrics import mean_squared_error,r2_score   # digunakan untuk evaluasi model\nfrom sklearn.model_selection import(   # digunakan untuk validasi silang dan hyperparameter tuning\n    train_test_split,\n    RandomizedSearchCV,\n    cross_val_score,\n)\nfrom sklearn import preprocessing   # digunakan untuk preprocessing data\nfrom sklearn.preprocessing import MinMaxScaler   # digunakan untuk menormalkan variabel dalam range 0-1\nfrom sklearn.svm import SVR   # digunakan untuk membangun model Support Vector Regression\nfrom scipy.stats import(   # digunakan untuk menghasilkan nilai acak untuk hyperparameter tuning\n    uniform,\n    randint,\n    )\nfrom sklearn.linear_model import (   # digunakan untuk membangun model regresi linear, ridge, dan lasso\n    LinearRegression,\n    Ridge,\n    Lasso\n)\nfrom sklearn.metrics import make_scorer\nimport math\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, hamming_loss, roc_auc_score\nfrom catboost import CatBoostClassifier\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, hamming_loss, roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nimport tensorflow as tf\nimport time\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import f1_score\nimport optuna # dugunakan untuk melakukan hyperparameter tuning\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.feature_selection import SelectPercentile, f_classif\nimport holidays\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:00:10.160785Z","iopub.execute_input":"2023-08-10T06:00:10.161241Z","iopub.status.idle":"2023-08-10T06:00:23.124712Z","shell.execute_reply.started":"2023-08-10T06:00:10.161192Z","shell.execute_reply":"2023-08-10T06:00:23.123827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\nfrom sklearn.preprocessing import LabelBinarizer,LabelEncoder,StandardScaler,MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier,LinearRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense,LSTM\nimport tensorflow as tf\nimport tqdm\nimport requests\nfrom sklearn.preprocessing import FunctionTransformer\n\nimport xml.etree.ElementTree as ET","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:00:23.126872Z","iopub.execute_input":"2023-08-10T06:00:23.128461Z","iopub.status.idle":"2023-08-10T06:00:23.598666Z","shell.execute_reply.started":"2023-08-10T06:00:23.128418Z","shell.execute_reply":"2023-08-10T06:00:23.597533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.linear_model import RANSACRegressor\nfrom sklearn.linear_model import HuberRegressor\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.isotonic import IsotonicRegression\nfrom bs4 import BeautifulSoup\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:00:23.600179Z","iopub.execute_input":"2023-08-10T06:00:23.600856Z","iopub.status.idle":"2023-08-10T06:00:23.855056Z","shell.execute_reply.started":"2023-08-10T06:00:23.600816Z","shell.execute_reply":"2023-08-10T06:00:23.853648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/ristek-datathon-2023/train.csv')\ntest=pd.read_csv('/kaggle/input/ristek-datathon-2023/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:39:58.158697Z","iopub.execute_input":"2023-08-09T18:39:58.160078Z","iopub.status.idle":"2023-08-09T18:39:58.76517Z","shell.execute_reply.started":"2023-08-09T18:39:58.160027Z","shell.execute_reply":"2023-08-09T18:39:58.764235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:58:51.021116Z","iopub.execute_input":"2023-08-09T18:58:51.021488Z","iopub.status.idle":"2023-08-09T18:58:51.816775Z","shell.execute_reply.started":"2023-08-09T18:58:51.021462Z","shell.execute_reply":"2023-08-09T18:58:51.815892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:02:00.885593Z","iopub.execute_input":"2023-08-09T19:02:00.886028Z","iopub.status.idle":"2023-08-09T19:02:01.131589Z","shell.execute_reply.started":"2023-08-09T19:02:00.885995Z","shell.execute_reply":"2023-08-09T19:02:01.130561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ekstraksi Data Eksternal","metadata":{}},{"cell_type":"markdown","source":"## Ekstraksi dari id_jalan","metadata":{}},{"cell_type":"code","source":"def extract_tags_from_osm(df, id_column, tags_to_extract):\n    fetched_xml_data = {}\n    \n    for index, row in df.iterrows():\n        id_value = row[id_column]\n        if id_value not in fetched_xml_data:\n            api_url = f\"https://www.openstreetmap.org/api/0.6/way/{id_value}\"\n            response = requests.get(api_url)\n            fetched_xml_data[id_value] = ET.fromstring(response.content)\n        \n        tree = fetched_xml_data[id_value]\n        \n        for tag in tags_to_extract:\n            tag_value = \"Not included\"\n            tag_element = tree.find(f'.//tag[@k=\"{tag}\"]')\n            if tag_element is not None:\n                tag_value = tag_element.get('v')\n            df.at[index, tag] = tag_value\n    \n    return df\n\n# Example usage with your 'train' DataFrame\ntags_to_extract = [\"busway\", \"cycleway\", \"foot\", \"highway\", \"lanes\", \"lit\", \"maxspeed\", \"name\", \"oneway\", \"operator\", \"sidewalk\", \"surface\",\"lanes:backward\",\"lanes:forward\"]\nprocessed_train = extract_tags_from_osm(train, 'id_jalan', tags_to_extract)\n\n# Example usage with your 'test' DataFrame\nprocessed_test = extract_tags_from_osm(test, 'id_jalan', tags_to_extract)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:49:53.140456Z","iopub.execute_input":"2023-08-09T18:49:53.140814Z","iopub.status.idle":"2023-08-09T18:52:50.910737Z","shell.execute_reply.started":"2023-08-09T18:49:53.140786Z","shell.execute_reply":"2023-08-09T18:52:50.909676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_train[tags_to_extract ].head()","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:07:19.339221Z","iopub.execute_input":"2023-08-09T19:07:19.339526Z","iopub.status.idle":"2023-08-09T19:07:19.405164Z","shell.execute_reply.started":"2023-08-09T19:07:19.339501Z","shell.execute_reply":"2023-08-09T19:07:19.403807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alls=['waktu_setempat', 'id_jalan', 'id_titik_mulai', 'id_titik_akhir']+tags_to_extract","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:26:02.660627Z","iopub.execute_input":"2023-08-09T19:26:02.660959Z","iopub.status.idle":"2023-08-09T19:26:02.666054Z","shell.execute_reply.started":"2023-08-09T19:26:02.660933Z","shell.execute_reply":"2023-08-09T19:26:02.664666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alls","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:26:04.830591Z","iopub.execute_input":"2023-08-09T19:26:04.831692Z","iopub.status.idle":"2023-08-09T19:26:04.838789Z","shell.execute_reply.started":"2023-08-09T19:26:04.831639Z","shell.execute_reply":"2023-08-09T19:26:04.837636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_train[alls].to_csv(\"id_jalan_train.csv\",index=False)\nprocessed_test[alls].to_csv(\"id_jalan_test.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:26:43.756405Z","iopub.execute_input":"2023-08-09T19:26:43.756814Z","iopub.status.idle":"2023-08-09T19:26:47.21555Z","shell.execute_reply.started":"2023-08-09T19:26:43.756785Z","shell.execute_reply":"2023-08-09T19:26:47.214842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ekstraksi dari id_titik_mulai dan id_titik_akhir","metadata":{}},{"cell_type":"code","source":"# Define a dictionary to store cached latitude and longitude data\ncached_data = {}\n\n# Define a function to fetch latitude and longitude for a given node ID\ndef fetch_lat_lon(node_id):\n    if node_id in cached_data:\n        return cached_data[node_id]\n    \n    url = f\"https://www.openstreetmap.org/node/{node_id}/history\"\n    response = requests.get(url)\n    \n    if response.status_code == 200:\n        soup = BeautifulSoup(response.content, 'html.parser')\n        longitude_elem = soup.find(class_='longitude')\n        latitude_elem = soup.find(class_='latitude')\n        \n        if longitude_elem and latitude_elem:\n            longitude = longitude_elem.get_text(strip=True)\n            latitude = latitude_elem.get_text(strip=True)\n            data = (latitude, longitude)\n            cached_data[node_id] = data\n            return data\n        else:\n            return None, None\n    else:\n        return None, None\n\n# Define a function to update latitude and longitude in a DataFrame\ndef update_lat_lon(df, id_column, lat_column, lon_column):\n    for index, row in df.iterrows():\n        node_id = row[id_column]\n        latitude, longitude = fetch_lat_lon(node_id)\n        \n        if latitude is not None and longitude is not None:\n            df.at[index, lat_column] = latitude\n            df.at[index, lon_column] = longitude\n        else:\n            print(f\"Latitude or longitude not found for ID {node_id}\")\n\n    # Fill missing values with NaN\n    df.fillna(value=float('nan'), inplace=True)\nupdate_lat_lon(processed_train, 'id_titik_mulai', 'latitude_awal', 'longitude_awal')\nupdate_lat_lon(processed_test, 'id_titik_mulai', 'latitude_awal', 'longitude_awal')\nupdate_lat_lon(processed_train, 'id_titik_akhir', 'latitude_akhir', 'longitude_akhir')\nupdate_lat_lon(processed_test, 'id_titik_akhir', 'latitude_akhir', 'longitude_akhir')","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:11:36.124343Z","iopub.execute_input":"2023-08-09T19:11:36.124672Z","iopub.status.idle":"2023-08-09T19:14:19.160863Z","shell.execute_reply.started":"2023-08-09T19:11:36.124648Z","shell.execute_reply":"2023-08-09T19:14:19.15948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_train[['latitude_awal', 'longitude_awal','latitude_akhir', 'longitude_akhir']].head()","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:23:03.494443Z","iopub.execute_input":"2023-08-09T19:23:03.494697Z","iopub.status.idle":"2023-08-09T19:23:03.521888Z","shell.execute_reply.started":"2023-08-09T19:23:03.494675Z","shell.execute_reply":"2023-08-09T19:23:03.520485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_train[['waktu_setempat', 'id_jalan', 'id_titik_mulai', 'id_titik_akhir','latitude_awal', 'longitude_awal','latitude_akhir', 'longitude_akhir']].to_csv(\"lon_lat_train.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:24:53.34001Z","iopub.execute_input":"2023-08-09T19:24:53.340381Z","iopub.status.idle":"2023-08-09T19:24:54.760441Z","shell.execute_reply.started":"2023-08-09T19:24:53.340352Z","shell.execute_reply":"2023-08-09T19:24:54.75974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_test[['waktu_setempat', 'id_jalan', 'id_titik_mulai', 'id_titik_akhir','latitude_awal', 'longitude_awal','latitude_akhir', 'longitude_akhir']].to_csv(\"lon_lat_test.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:25:05.61267Z","iopub.execute_input":"2023-08-09T19:25:05.613057Z","iopub.status.idle":"2023-08-09T19:25:06.052105Z","shell.execute_reply.started":"2023-08-09T19:25:05.613033Z","shell.execute_reply":"2023-08-09T19:25:06.050781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=processed_train.copy()\ntest=processed_test.copy()","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:42:09.456841Z","iopub.execute_input":"2023-08-09T19:42:09.457194Z","iopub.status.idle":"2023-08-09T19:42:09.534362Z","shell.execute_reply.started":"2023-08-09T19:42:09.457166Z","shell.execute_reply":"2023-08-09T19:42:09.532794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:42:10.539119Z","iopub.execute_input":"2023-08-09T19:42:10.539493Z","iopub.status.idle":"2023-08-09T19:42:10.546038Z","shell.execute_reply.started":"2023-08-09T19:42:10.539464Z","shell.execute_reply":"2023-08-09T19:42:10.544241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"## Ekstraksi variabel waktu dari \"waktu_setempat\"","metadata":{}},{"cell_type":"code","source":"def process_datetime_columns(df, datetime_column):\n    df['waktu_setempat'] = pd.to_datetime(df[datetime_column], format=\"%Y-%m-%d %H:%M:%S\")\n    df['year'] = df['waktu_setempat'].dt.year\n    df['month'] = df['waktu_setempat'].dt.month\n    df['day'] = df['waktu_setempat'].dt.day\n    df['hour'] = df['waktu_setempat'].dt.hour\n    df['weekday'] = df['waktu_setempat'].dt.weekday\n    return df\n\n# Example usage with your 'train' DataFrame\ntrain = process_datetime_columns(train, 'waktu_setempat')\ntest= process_datetime_columns(test, 'waktu_setempat')","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:42:14.94028Z","iopub.execute_input":"2023-08-09T19:42:14.940648Z","iopub.status.idle":"2023-08-09T19:42:15.16243Z","shell.execute_reply.started":"2023-08-09T19:42:14.940619Z","shell.execute_reply":"2023-08-09T19:42:15.161447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ekstraksi Hari spesial","metadata":{}},{"cell_type":"code","source":"def holiday(date):\n    if date == 10:\n        return \"Tu B'Shevat\"\n    if date == 14:\n        return \"Valentine\"\n    if date == 21:\n        return 'Maha Shivaratri'\n    if date == 25:\n        return 'Carnival / Shrove Tuesday / Pancake Day'\n    if date == 26:\n        return 'Carnival / Ash Wednesday'\n    return 'Not Holiday'\n    \ntrain['holiday'] = train.apply(lambda row: holiday(row['day']), axis=1)\ntest['holiday']=test.apply(lambda row: holiday(row['day']), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:42:17.742707Z","iopub.execute_input":"2023-08-09T19:42:17.743101Z","iopub.status.idle":"2023-08-09T19:42:22.616693Z","shell.execute_reply.started":"2023-08-09T19:42:17.743073Z","shell.execute_reply":"2023-08-09T19:42:22.615085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Konversi fitur maxspeed menjadi int","metadata":{}},{"cell_type":"code","source":"train[['id_jalan', 'id_titik_mulai', 'id_titik_akhir','latitude_awal', 'longitude_awal','latitude_akhir', 'longitude_akhir']].head()","metadata":{"execution":{"iopub.status.busy":"2023-08-09T20:55:54.150755Z","iopub.execute_input":"2023-08-09T20:55:54.151093Z","iopub.status.idle":"2023-08-09T20:55:54.178188Z","shell.execute_reply.started":"2023-08-09T20:55:54.151064Z","shell.execute_reply":"2023-08-09T20:55:54.177218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_maxspeed_to_int(df):\n    for index, row in df.iterrows():\n        maxspeed_value = row['maxspeed']\n        if maxspeed_value != \"Not included\" and isinstance( maxspeed_value,str):\n            maxspeed_value = int(maxspeed_value.split()[0])  # Extract the numeric part\n        df.at[index, 'maxspeed'] = maxspeed_value\n    return df\n\n# Example usage with the processed 'test' DataFrame\ntest = convert_maxspeed_to_int(test)\ntrain = convert_maxspeed_to_int(train)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:42:29.594262Z","iopub.execute_input":"2023-08-09T19:42:29.594689Z","iopub.status.idle":"2023-08-09T19:43:06.081193Z","shell.execute_reply.started":"2023-08-09T19:42:29.594655Z","shell.execute_reply":"2023-08-09T19:43:06.079825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Menghitung fitur distance dari fitur longitude dan latitude menggunakan rumus haversine\n","metadata":{}},{"cell_type":"code","source":"def haversine_distance(lat1, lon1, lat2, lon2):\n    R = 6371  # Radius of the Earth in kilometers\n\n    # Convert latitude and longitude from degrees to radians\n    lat1_rad = math.radians(lat1)\n    lon1_rad = math.radians(lon1)\n    lat2_rad = math.radians(lat2)\n    lon2_rad = math.radians(lon2)\n\n    # Differences in coordinates\n    dlat = lat2_rad - lat1_rad\n    dlon = lon2_rad - lon1_rad\n\n    # Haversine formula\n    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = R * c\n\n    return distance\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:43:10.346916Z","iopub.execute_input":"2023-08-09T19:43:10.347839Z","iopub.status.idle":"2023-08-09T19:43:10.354412Z","shell.execute_reply.started":"2023-08-09T19:43:10.347809Z","shell.execute_reply":"2023-08-09T19:43:10.35329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Convert latitude and longitude columns to float\ntrain['latitude_awal'] = train['latitude_awal'].astype(float)\ntrain['longitude_awal'] = train['longitude_awal'].astype(float)\ntrain['latitude_akhir'] = train['latitude_akhir'].astype(float)\ntrain['longitude_akhir'] = train['longitude_akhir'].astype(float)\n# Convert latitude and longitude columns to float\ntest['latitude_awal'] = test['latitude_awal'].astype(float)\ntest['longitude_awal'] = test['longitude_awal'].astype(float)\ntest['latitude_akhir'] = test['latitude_akhir'].astype(float)\ntest['longitude_akhir'] = test['longitude_akhir'].astype(float)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:43:14.289196Z","iopub.execute_input":"2023-08-09T19:43:14.289569Z","iopub.status.idle":"2023-08-09T19:43:14.787036Z","shell.execute_reply.started":"2023-08-09T19:43:14.289541Z","shell.execute_reply":"2023-08-09T19:43:14.785629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['distance'] = train.apply(lambda row: haversine_distance(row['latitude_awal'], row['longitude_awal'], row['latitude_akhir'], row['longitude_akhir']), axis=1)\ntest['distance'] = test.apply(lambda row: haversine_distance(row['latitude_awal'], row['longitude_awal'], row['latitude_akhir'], row['longitude_akhir']), axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:43:16.978247Z","iopub.execute_input":"2023-08-09T19:43:16.978836Z","iopub.status.idle":"2023-08-09T19:43:27.714487Z","shell.execute_reply.started":"2023-08-09T19:43:16.978807Z","shell.execute_reply":"2023-08-09T19:43:27.713513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[[\"distance\"]].head()","metadata":{"execution":{"iopub.status.busy":"2023-08-09T20:54:41.530751Z","iopub.execute_input":"2023-08-09T20:54:41.53113Z","iopub.status.idle":"2023-08-09T20:54:41.542671Z","shell.execute_reply.started":"2023-08-09T20:54:41.531097Z","shell.execute_reply":"2023-08-09T20:54:41.541295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Menggunakan cos dan sinus Transformer untuk fitur day,hour,dan weekday","metadata":{}},{"cell_type":"code","source":"def add_sine_cosine_features(df,test, column_name, period):\n    sin_transformer = FunctionTransformer(lambda x: np.sin(2 * np.pi * x / period))\n    cos_transformer = FunctionTransformer(lambda x: np.cos(2 * np.pi * x / period))\n    \n    df[f'{column_name}_sin'] = sin_transformer.fit_transform(df[[column_name]])\n    df[f'{column_name}_cos'] = cos_transformer.fit_transform(df[[column_name]])\n    \n#     test_df[f'{column_name}_sin'] = sin_transformer.transform(test_df[[column_name]])\n#     test_df[f'{column_name}_cos'] = cos_transformer.transform(test_df[[column_name]])\n    test[f'{column_name}_sin'] = sin_transformer.transform(test[[column_name]])\n    test[f'{column_name}_cos'] = cos_transformer.transform(test[[column_name]])\n    return df,test\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:43:34.141735Z","iopub.execute_input":"2023-08-09T19:43:34.14209Z","iopub.status.idle":"2023-08-09T19:43:34.149313Z","shell.execute_reply.started":"2023-08-09T19:43:34.142063Z","shell.execute_reply":"2023-08-09T19:43:34.148062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:43:36.051543Z","iopub.execute_input":"2023-08-09T19:43:36.05264Z","iopub.status.idle":"2023-08-09T19:43:36.058132Z","shell.execute_reply.started":"2023-08-09T19:43:36.052603Z","shell.execute_reply":"2023-08-09T19:43:36.057478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train,test=add_sine_cosine_features(train,test, 'hour', 24)\ntrain,test=add_sine_cosine_features(train,test, 'day', 29)\ntrain,test=add_sine_cosine_features(train,test, 'weekday', 7)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:43:39.422006Z","iopub.execute_input":"2023-08-09T19:43:39.422346Z","iopub.status.idle":"2023-08-09T19:43:39.526434Z","shell.execute_reply.started":"2023-08-09T19:43:39.422321Z","shell.execute_reply":"2023-08-09T19:43:39.525362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.to_csv(\"finalisasi_train.csv\",index=False)\ntest.to_csv(\"finalisasi_test.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:46:06.736573Z","iopub.execute_input":"2023-08-09T19:46:06.73699Z","iopub.status.idle":"2023-08-09T19:46:18.329655Z","shell.execute_reply.started":"2023-08-09T19:46:06.73696Z","shell.execute_reply":"2023-08-09T19:46:18.328162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[[\"hour_sin\",\"day_sin\",\"weekday_sin\",\"hour_cos\",\"day_cos\",\"weekday_cos\",\"distance\"]].head()","metadata":{"execution":{"iopub.status.busy":"2023-08-09T21:07:49.78123Z","iopub.execute_input":"2023-08-09T21:07:49.781616Z","iopub.status.idle":"2023-08-09T21:07:49.801478Z","shell.execute_reply.started":"2023-08-09T21:07:49.781585Z","shell.execute_reply":"2023-08-09T21:07:49.800778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label Encoder","metadata":{}},{"cell_type":"code","source":"lb_year = LabelEncoder()\ntrain['year'] = lb_year.fit_transform(train['year'])\n\nlb_id_jalan=LabelEncoder()\ntrain['id_jalan'] = lb_id_jalan.fit_transform(train['id_jalan'])\n\nlb_id_titik_mulai=LabelEncoder()\ntrain['id_titik_mulai'] = lb_id_titik_mulai.fit_transform(train['id_titik_mulai'])\n\nlb_id_titik_akhir=LabelEncoder()\ntrain['id_titik_akhir'] = lb_id_titik_akhir.fit_transform(train['id_titik_akhir'])\n# Transform the 'year' column in test using the label encoder fitted on the training data\ntest['year'] = lb_year.transform(test['year'])\n\n# Transform the 'id_jalan' column in test using the label encoder fitted on the training data\ntest['id_jalan'] = lb_id_jalan.transform(test['id_jalan'])\n\n# Transform the 'id_titik_mulai' column in test using the label encoder fitted on the training data\ntest['id_titik_mulai'] = lb_id_titik_mulai.transform(test['id_titik_mulai'])\n\n# Transform the 'id_titik_akhir' column in test using the label encoder fitted on the training data\ntest['id_titik_akhir'] = lb_id_titik_akhir.transform(test['id_titik_akhir'])\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:59:39.423055Z","iopub.execute_input":"2023-08-09T19:59:39.423484Z","iopub.status.idle":"2023-08-09T19:59:39.574548Z","shell.execute_reply.started":"2023-08-09T19:59:39.423454Z","shell.execute_reply":"2023-08-09T19:59:39.573782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize LabelEncoder\nnp.random.seed(42)\nlabel_encoder = LabelEncoder()\n\n# Loop through each column in the DataFrame\nfor column in train.columns:\n    # Check if the column data type is non-integer (object)\n    if train[column].dtype == 'object':\n        # Convert column to string before fitting the label encoder\n        train[column] = train[column].astype(str)\n        test[column] = test[column].astype(str)\n        \n        # Fit the label encoder on the train data\n        label_encoder.fit(train[column])\n        \n        # Transform train data\n        train[column] = label_encoder.transform(train[column])\n        \n        # Transform test data with handling of unseen categories\n        test[column] = test[column].apply(lambda x: label_encoder.transform([x])[0] if x in label_encoder.classes_ else -1)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T19:59:48.327665Z","iopub.execute_input":"2023-08-09T19:59:48.328646Z","iopub.status.idle":"2023-08-09T20:01:24.735733Z","shell.execute_reply.started":"2023-08-09T19:59:48.328614Z","shell.execute_reply":"2023-08-09T20:01:24.734508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split Data","metadata":{}},{"cell_type":"code","source":"def clean_column_name(column_name):\n    cleaned_name = re.sub('[^A-Za-z0-9]+', '_', column_name)\n    return cleaned_name\n\n# Rename the columns in train data\ntrain.rename(columns={\n    'lanes:backward': clean_column_name('lanes:backward'),\n    'lanes:forward': clean_column_name('lanes:forward')\n}, inplace=True)\n\n# Rename the columns in test data\ntest.rename(columns={\n    'lanes:backward': clean_column_name('lanes:backward'),\n    'lanes:forward': clean_column_name('lanes:forward')\n}, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T21:26:56.348497Z","iopub.execute_input":"2023-08-09T21:26:56.348859Z","iopub.status.idle":"2023-08-09T21:26:56.356014Z","shell.execute_reply.started":"2023-08-09T21:26:56.348833Z","shell.execute_reply":"2023-08-09T21:26:56.354683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2023-08-09T21:27:02.274763Z","iopub.execute_input":"2023-08-09T21:27:02.275116Z","iopub.status.idle":"2023-08-09T21:27:02.282498Z","shell.execute_reply.started":"2023-08-09T21:27:02.27509Z","shell.execute_reply":"2023-08-09T21:27:02.281578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.to_csv(\"after_train_encode.csv\",index=False)\ntest.to_csv(\"after_test_encode.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T22:47:18.769786Z","iopub.execute_input":"2023-08-09T22:47:18.770196Z","iopub.status.idle":"2023-08-09T22:47:29.002321Z","shell.execute_reply.started":"2023-08-09T22:47:18.770166Z","shell.execute_reply":"2023-08-09T22:47:29.000449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.DataFrame()\ntest_data = pd.DataFrame()\n\ntest_percentage=0.2\nunique_series = train[['id_jalan', 'id_titik_mulai', 'id_titik_akhir']].drop_duplicates()\nfor idx, series in unique_series.iterrows():\n    series_data = train.loc[(train['id_jalan'] == series['id_jalan']) & \n                         (train['id_titik_mulai'] == series['id_titik_mulai']) & \n                         (train['id_titik_akhir'] == series['id_titik_akhir'])]\n    split_index = int(len(series_data) * (1 - test_percentage))\n    train_data = pd.concat([train_data, series_data.iloc[:split_index]])\n    test_data = pd.concat([test_data, series_data.iloc[split_index:]])","metadata":{"execution":{"iopub.status.busy":"2023-08-09T21:27:19.188811Z","iopub.execute_input":"2023-08-09T21:27:19.189172Z","iopub.status.idle":"2023-08-09T21:27:29.436494Z","shell.execute_reply.started":"2023-08-09T21:27:19.189144Z","shell.execute_reply":"2023-08-09T21:27:29.434874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=train_data.drop(['rerata_kecepatan','lit','waktu_setempat'],axis=1)\ny=train_data['rerata_kecepatan']\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T21:27:53.948831Z","iopub.execute_input":"2023-08-09T21:27:53.949176Z","iopub.status.idle":"2023-08-09T21:27:53.966967Z","shell.execute_reply.started":"2023-08-09T21:27:53.94915Z","shell.execute_reply":"2023-08-09T21:27:53.965547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test2=test_data.drop(['rerata_kecepatan','lit','waktu_setempat'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T21:27:55.190378Z","iopub.execute_input":"2023-08-09T21:27:55.191359Z","iopub.status.idle":"2023-08-09T21:27:55.201844Z","shell.execute_reply.started":"2023-08-09T21:27:55.191325Z","shell.execute_reply":"2023-08-09T21:27:55.200446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_=test.drop(['lit','waktu_setempat','id'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T21:27:58.24088Z","iopub.execute_input":"2023-08-09T21:27:58.241368Z","iopub.status.idle":"2023-08-09T21:27:58.271473Z","shell.execute_reply.started":"2023-08-09T21:27:58.241326Z","shell.execute_reply":"2023-08-09T21:27:58.269764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2023-08-09T21:28:00.076482Z","iopub.execute_input":"2023-08-09T21:28:00.076945Z","iopub.status.idle":"2023-08-09T21:28:00.155827Z","shell.execute_reply.started":"2023-08-09T21:28:00.076913Z","shell.execute_reply":"2023-08-09T21:28:00.155022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_","metadata":{"execution":{"iopub.status.busy":"2023-08-09T21:28:01.252672Z","iopub.execute_input":"2023-08-09T21:28:01.253688Z","iopub.status.idle":"2023-08-09T21:28:01.2901Z","shell.execute_reply.started":"2023-08-09T21:28:01.253655Z","shell.execute_reply":"2023-08-09T21:28:01.288803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"import pickle\nimport time\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, BaggingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, HuberRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.linear_model import RANSACRegressor\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.isotonic import IsotonicRegression\nimport lightgbm as lgb\nimport xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2023-08-09T21:18:50.92103Z","iopub.execute_input":"2023-08-09T21:18:50.921383Z","iopub.status.idle":"2023-08-09T21:18:50.928288Z","shell.execute_reply.started":"2023-08-09T21:18:50.921354Z","shell.execute_reply":"2023-08-09T21:18:50.926885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef smape(actual, forecast):\n    return 100 * np.mean(2 * np.abs(actual - forecast) / (np.abs(actual) + np.abs(forecast)))","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:01:14.26899Z","iopub.execute_input":"2023-08-10T06:01:14.270212Z","iopub.status.idle":"2023-08-10T06:01:14.276485Z","shell.execute_reply.started":"2023-08-10T06:01:14.270172Z","shell.execute_reply":"2023-08-10T06:01:14.275275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nimport time\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, HuberRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport lightgbm as lgb\nfrom sklearn.model_selection import cross_val_score\n\n\n# Define the models\nmodels = [\n    ('Linear Regression', LinearRegression()),\n    ('Ridge', Ridge()),\n    ('Lasso', Lasso()),\n    ('ElasticNet', ElasticNet()),\n    ('Huber', HuberRegressor()),\n    ('Random Forest', RandomForestRegressor(random_state=42)),\n    ('LightGBM', lgb.LGBMRegressor(random_state=42)),\n     ('XGBoost', xgb.XGBRegressor(random_state=42))\n]\n\n# Create a DataFrame to store the results\nresults_df = pd.DataFrame(columns=['Model', 'Time', 'SMAPE', 'CV_Mean', 'CV_Std'])\n\n# Iterate through each model, fit it, and print the RMSE\nfor model_name, model in models:\n    start_time = time.time()\n    \n    # Perform cross-validation\n    cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n    avg_cv_score = np.mean(-cv_scores)\n    std_cv_score = np.std(-cv_scores)\n    model.fit(X,y)\n    elapsed_time = time.time() - start_time\n    \n    y_pred = model.predict(test2)\n    smape_model = smape(test_data['rerata_kecepatan'], y_pred)\n    \n    print(f\"{model_name} - SMAPE:\", smape_model)\n    \n    results_df = results_df.append({'Model': model_name, 'Time': elapsed_time, 'SMAPE': smape_model, 'CV_Mean': avg_cv_score, 'CV_Std': std_cv_score}, ignore_index=True)\n\n# Save the results DataFrame to a CSV file\nresults_df.to_csv('model_results.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T21:28:36.168135Z","iopub.execute_input":"2023-08-09T21:28:36.168482Z","iopub.status.idle":"2023-08-09T21:55:41.036368Z","shell.execute_reply.started":"2023-08-09T21:28:36.168455Z","shell.execute_reply":"2023-08-09T21:55:41.035009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df.sort_values(by='SMAPE')","metadata":{"execution":{"iopub.status.busy":"2023-08-09T22:00:11.257092Z","iopub.execute_input":"2023-08-09T22:00:11.257488Z","iopub.status.idle":"2023-08-09T22:00:11.272348Z","shell.execute_reply.started":"2023-08-09T22:00:11.257458Z","shell.execute_reply":"2023-08-09T22:00:11.270304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df","metadata":{"execution":{"iopub.status.busy":"2023-08-09T21:23:50.272579Z","iopub.execute_input":"2023-08-09T21:23:50.272961Z","iopub.status.idle":"2023-08-09T21:23:50.284193Z","shell.execute_reply.started":"2023-08-09T21:23:50.272932Z","shell.execute_reply":"2023-08-09T21:23:50.283104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## HyperParameter Tuning\n","metadata":{}},{"cell_type":"code","source":"from hyperopt import fmin, tpe, hp\nimport lightgbm as lgb\n\n# Define the objective function to minimize (SMAPE)\ndef objective(params):\n    model = lgb.LGBMRegressor(\n        n_estimators=int(params['n_estimators']),\n        max_depth=int(params['max_depth']),\n        min_child_samples=int(params['min_child_samples']),\n        learning_rate=params['learning_rate'],\n        colsample_bytree=params['colsample_bytree'],\n        subsample=params['subsample'],\n        reg_alpha=params['reg_alpha'],\n        reg_lambda=params['reg_lambda'],\n        min_child_weight=params['min_child_weight'],\n        subsample_freq=int(params['subsample_freq']),\n        num_leaves=int(params['num_leaves']),\n        min_data_in_leaf=int(params['min_data_in_leaf']),\n        bagging_fraction=params['bagging_fraction'],\n        bagging_freq=int(params['bagging_freq']),\n        feature_fraction=params['feature_fraction'],\n        lambda_l1=params['lambda_l1'],\n        lambda_l2=params['lambda_l2'],\n        random_state=42\n    )\n    model.fit(X, y)\n    y_pred = model.predict(test2)\n    smape_score = smape(test_data['rerata_kecepatan'], y_pred)\n    feature_importances = model.get_params()\n\n    print(f\"smape : {smape_score} params : {feature_importances}\")\n#     predicted = model.predict(test)  # Use X_test_selected instead of test\n#     subs['rerata_kecepatan'] = predicted\n    \n#     subs_filename = f'/kaggle/working/submission_baru.csv'\n#     subs.to_csv(subs_filename, index=False)\n    \n#     print(f\"Submission saved for submission\")\n    \n    return smape_score\n\nspace = {\n    'n_estimators': hp.quniform('n_estimators', 10, 1000, 10),\n    'max_depth': hp.quniform('max_depth', 3, 100, 1),\n    'min_child_samples': hp.quniform('min_child_samples', 1, 100, 1),\n    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.8)),\n    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n    'subsample': hp.uniform('subsample', 0.5, 1),\n    'reg_alpha': hp.loguniform('reg_alpha', np.log(1e-10), np.log(1)),\n    'reg_lambda': hp.loguniform('reg_lambda', np.log(1e-10), np.log(1)),\n    'min_child_weight': hp.loguniform('min_child_weight', np.log(1e-3), np.log(10)),\n    'subsample_freq': hp.quniform('subsample_freq', 1, 10, 1),\n    'num_leaves': hp.quniform('num_leaves', 8, 128, 1),\n    'min_data_in_leaf': hp.quniform('min_data_in_leaf', 10, 100, 1),\n    'bagging_fraction': hp.uniform('bagging_fraction', 0.5, 1),\n    'bagging_freq': hp.quniform('bagging_freq', 1, 10, 1),\n    'feature_fraction': hp.uniform('feature_fraction', 0.5, 1),\n    'lambda_l1': hp.loguniform('lambda_l1', np.log(1e-10), np.log(10)),\n    'lambda_l2': hp.loguniform('lambda_l2', np.log(1e-10), np.log(10)),\n}\n\n# Run hyperparameter tuning\nbest = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=500)\n\nprint(\"Best hyperparameters:\", best)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T22:20:37.908563Z","iopub.execute_input":"2023-08-09T22:20:37.910344Z","iopub.status.idle":"2023-08-09T22:46:27.13373Z","shell.execute_reply.started":"2023-08-09T22:20:37.910301Z","shell.execute_reply":"2023-08-09T22:46:27.131549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from hyperopt import fmin, tpe, hp\nimport lightgbm as lgb\n\n# Define the objective function to minimize (SMAPE)\ndef objective(params):\n    model = lgb.LGBMRegressor(\n        n_estimators=int(params['n_estimators']),\n        max_depth=int(params['max_depth']),\n        min_child_samples=int(params['min_child_samples']),\n        learning_rate=params['learning_rate'],\n        colsample_bytree=params['colsample_bytree'],\n        subsample=params['subsample'],\n        reg_alpha=params['reg_alpha'],\n        reg_lambda=params['reg_lambda'],\n        min_child_weight=params['min_child_weight'],\n        subsample_freq=int(params['subsample_freq']),\n        num_leaves=int(params['num_leaves']),\n        min_data_in_leaf=int(params['min_data_in_leaf']),\n        bagging_fraction=params['bagging_fraction'],\n        bagging_freq=int(params['bagging_freq']),\n        feature_fraction=params['feature_fraction'],\n        lambda_l1=params['lambda_l1'],\n        lambda_l2=params['lambda_l2'],\n        random_state=42\n    )\n    model.fit(X, y)\n    y_pred = model.predict(test2)\n    smape_score = smape(test_data['rerata_kecepatan'], y_pred)\n    feature_importances = model.get_params()\n\n    print(f\"smape : {smape_score} params : {feature_importances}\")\n#     predicted = model.predict(test)  # Use X_test_selected instead of test\n#     subs['rerata_kecepatan'] = predicted\n    \n#     subs_filename = f'/kaggle/working/submission_baru.csv'\n#     subs.to_csv(subs_filename, index=False)\n    \n#     print(f\"Submission saved for submission\")\n    \n    return smape_score\n\nspace = {\n    'n_estimators': hp.quniform('n_estimators', 10, 1000, 10),\n    'max_depth': hp.quniform('max_depth', 3, 100, 1),\n    'min_child_samples': hp.quniform('min_child_samples', 1, 100, 1),\n    'learning_rate': hp.loguniform('learning_rate', np.log(0.009), np.log(0.8)),\n    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n    'subsample': hp.uniform('subsample', 0.5, 1),\n    'reg_alpha': hp.loguniform('reg_alpha', np.log(1e-10), np.log(1)),\n    'reg_lambda': hp.loguniform('reg_lambda', np.log(1e-10), np.log(1)),\n    'min_child_weight': hp.loguniform('min_child_weight', np.log(1e-3), np.log(10)),\n    'subsample_freq': hp.quniform('subsample_freq', 1, 10, 1),\n    'num_leaves': hp.quniform('num_leaves', 8, 128, 1),\n    'min_data_in_leaf': hp.quniform('min_data_in_leaf', 10, 100, 1),\n    'bagging_fraction': hp.uniform('bagging_fraction', 0.5, 1),\n    'bagging_freq': hp.quniform('bagging_freq', 1, 10, 1),\n    'feature_fraction': hp.uniform('feature_fraction', 0.5, 1),\n    'lambda_l1': hp.loguniform('lambda_l1', np.log(1e-10), np.log(10)),\n    'lambda_l2': hp.loguniform('lambda_l2', np.log(1e-10), np.log(10)),\n}\n\n# Run hyperparameter tuning\nbest = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=500)\n\nprint(\"Best hyperparameters:\", best)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T22:48:08.268494Z","iopub.execute_input":"2023-08-09T22:48:08.268893Z","iopub.status.idle":"2023-08-10T04:34:13.054353Z","shell.execute_reply.started":"2023-08-09T22:48:08.268862Z","shell.execute_reply":"2023-08-10T04:34:13.052655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/final-dataset-datathonuiristek/after_train_encode.csv')\ntest=pd.read_csv('/kaggle/input/final-dataset-datathonuiristek/after_test_encode.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:00:57.598171Z","iopub.execute_input":"2023-08-10T06:00:57.599896Z","iopub.status.idle":"2023-08-10T06:01:01.38564Z","shell.execute_reply.started":"2023-08-10T06:00:57.599829Z","shell.execute_reply":"2023-08-10T06:01:01.384584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_column_name(column_name):\n    cleaned_name = re.sub('[^A-Za-z0-9]+', '_', column_name)\n    return cleaned_name\n\n# Rename the columns in train data\ntrain.rename(columns={\n    'lanes:backward': clean_column_name('lanes:backward'),\n    'lanes:forward': clean_column_name('lanes:forward')\n}, inplace=True)\n\n# Rename the columns in test data\ntest.rename(columns={\n    'lanes:backward': clean_column_name('lanes:backward'),\n    'lanes:forward': clean_column_name('lanes:forward')\n}, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:01:04.407481Z","iopub.execute_input":"2023-08-10T06:01:04.407907Z","iopub.status.idle":"2023-08-10T06:01:04.42281Z","shell.execute_reply.started":"2023-08-10T06:01:04.407877Z","shell.execute_reply":"2023-08-10T06:01:04.421521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.DataFrame()\ntest_data = pd.DataFrame()\n\ntest_percentage=0.2\nunique_series = train[['id_jalan', 'id_titik_mulai', 'id_titik_akhir']].drop_duplicates()\nfor idx, series in unique_series.iterrows():\n    series_data = train.loc[(train['id_jalan'] == series['id_jalan']) & \n                         (train['id_titik_mulai'] == series['id_titik_mulai']) & \n                         (train['id_titik_akhir'] == series['id_titik_akhir'])]\n    split_index = int(len(series_data) * (1 - test_percentage))\n    train_data = pd.concat([train_data, series_data.iloc[:split_index]])\n    test_data = pd.concat([test_data, series_data.iloc[split_index:]])","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:14:10.441998Z","iopub.execute_input":"2023-08-10T06:14:10.442603Z","iopub.status.idle":"2023-08-10T06:14:29.809249Z","shell.execute_reply.started":"2023-08-10T06:14:10.442563Z","shell.execute_reply":"2023-08-10T06:14:29.808362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_data = pd.DataFrame()\ntest_data = pd.DataFrame()\n\nunique_series = train[['id_jalan', 'id_titik_mulai', 'id_titik_akhir']].drop_duplicates()\n\nfor idx, series in unique_series.iterrows():\n    series_data = train.loc[(train['id_jalan'] == series['id_jalan']) & \n                            (train['id_titik_mulai'] == series['id_titik_mulai']) & \n                            (train['id_titik_akhir'] == series['id_titik_akhir'])]\n    \n    # Split the data consistently\n    train_series_data, test_series_data = train_test_split(series_data, test_size=test_percentage, random_state=42)\n    \n    train_data = pd.concat([train_data, train_series_data])\n    test_data = pd.concat([test_data, test_series_data])","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:07:23.207641Z","iopub.execute_input":"2023-08-10T06:07:23.20802Z","iopub.status.idle":"2023-08-10T06:07:43.733602Z","shell.execute_reply.started":"2023-08-10T06:07:23.207992Z","shell.execute_reply":"2023-08-10T06:07:43.732452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=train_data.drop(['rerata_kecepatan','lit','waktu_setempat'],axis=1)\ny=train_data['rerata_kecepatan']\ntest2=test_data.drop(['rerata_kecepatan','lit','waktu_setempat'],axis=1)\ntest_=test.drop(['lit','waktu_setempat','id'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:14:35.49917Z","iopub.execute_input":"2023-08-10T06:14:35.499914Z","iopub.status.idle":"2023-08-10T06:14:35.536314Z","shell.execute_reply.started":"2023-08-10T06:14:35.499877Z","shell.execute_reply":"2023-08-10T06:14:35.535033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the hyperparameters\nimport lightgbm as lgb\nhyperparameters = {\n    'bagging_fraction': 0.8755808259764284,\n    'bagging_freq': 7,\n    'colsample_bytree': 0.6986775242324904,\n    'feature_fraction': 0.7030964143192601,\n    'lambda_l1': 9.721190480216267,\n    'lambda_l2': 8.688347081675282e-10,\n    'learning_rate': 0.042325537734418946,\n    'max_depth': 58,\n    'min_child_samples': 20,\n    'min_child_weight': 7.690738102055157,\n    'min_data_in_leaf': 27,\n    'n_estimators': 860,\n    'num_leaves': 122,\n    'reg_alpha': 4.8241807763984715e-06,\n    'reg_lambda': 0.28821417300340907,\n    'subsample': 0.667163499608758,\n    'subsample_freq': 8\n}\n\n# Create the LGBMRegressor model\nmodel = lgb.LGBMRegressor(**hyperparameters,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:08:26.60718Z","iopub.execute_input":"2023-08-10T06:08:26.607897Z","iopub.status.idle":"2023-08-10T06:08:26.614626Z","shell.execute_reply.started":"2023-08-10T06:08:26.607866Z","shell.execute_reply":"2023-08-10T06:08:26.613628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Best hyperparameters: {'bagging_fraction': 0.8755808259764284, 'bagging_freq': 7.0, 'colsample_bytree': 0.6986775242324904, 'feature_fraction': 0.7030964143192601, 'lambda_l1': 9.721190480216267, 'lambda_l2': 8.688347081675282e-10, 'learning_rate': 0.042325537734418946, 'max_depth': 58.0, 'min_child_samples': 20.0, 'min_child_weight': 7.690738102055157, 'min_data_in_leaf': 27.0, 'n_estimators': 860.0,\n                       'num_leaves': 122.0, 'reg_alpha': 4.8241807763984715e-06, 'reg_lambda': 0.28821417300340907, 'subsample': 0.667163499608758, 'subsample_freq': 8.0}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:08:29.854808Z","iopub.execute_input":"2023-08-10T06:08:29.855181Z","iopub.status.idle":"2023-08-10T06:09:18.863372Z","shell.execute_reply.started":"2023-08-10T06:08:29.855152Z","shell.execute_reply":"2023-08-10T06:09:18.862266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smape(test_data.rerata_kecepatan,model.predict(test2))","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:09:24.408818Z","iopub.execute_input":"2023-08-10T06:09:24.409182Z","iopub.status.idle":"2023-08-10T06:09:27.904016Z","shell.execute_reply.started":"2023-08-10T06:09:24.409152Z","shell.execute_reply":"2023-08-10T06:09:27.902846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subs=pd.read_csv(\"/kaggle/input/ristek-datathon-2023/sample_submission.csv\")\nsubs.rerata_kecepatan=model.predict(test_)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:10:42.385511Z","iopub.execute_input":"2023-08-10T06:10:42.385938Z","iopub.status.idle":"2023-08-10T06:10:47.826685Z","shell.execute_reply.started":"2023-08-10T06:10:42.385905Z","shell.execute_reply":"2023-08-10T06:10:47.825431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subs.to_csv(\"final.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:10:57.901507Z","iopub.execute_input":"2023-08-10T06:10:57.901929Z","iopub.status.idle":"2023-08-10T06:10:58.428023Z","shell.execute_reply.started":"2023-08-10T06:10:57.901897Z","shell.execute_reply":"2023-08-10T06:10:58.426854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subs","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:11:00.833376Z","iopub.execute_input":"2023-08-10T06:11:00.833787Z","iopub.status.idle":"2023-08-10T06:11:00.847128Z","shell.execute_reply.started":"2023-08-10T06:11:00.833757Z","shell.execute_reply":"2023-08-10T06:11:00.845958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:14:45.609707Z","iopub.execute_input":"2023-08-10T06:14:45.610114Z","iopub.status.idle":"2023-08-10T06:15:33.443288Z","shell.execute_reply.started":"2023-08-10T06:14:45.610084Z","shell.execute_reply":"2023-08-10T06:15:33.442188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smape(test_data.rerata_kecepatan,model.predict(test2))","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:15:33.445019Z","iopub.execute_input":"2023-08-10T06:15:33.445367Z","iopub.status.idle":"2023-08-10T06:15:36.635098Z","shell.execute_reply.started":"2023-08-10T06:15:33.445339Z","shell.execute_reply":"2023-08-10T06:15:36.634167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline Untuk Predict","metadata":{}},{"cell_type":"markdown","source":"Untuk reproduksi model ulang, run semua kode dibawah","metadata":{}},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2023-08-10T16:21:10.460084Z","iopub.execute_input":"2023-08-10T16:21:10.460534Z","iopub.status.idle":"2023-08-10T16:21:24.992194Z","shell.execute_reply.started":"2023-08-10T16:21:10.460500Z","shell.execute_reply":"2023-08-10T16:21:24.990902Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.65.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport gdown\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n# Define the hyperparameters\nimport lightgbm as lgb","metadata":{"execution":{"iopub.status.busy":"2023-08-10T16:21:24.994678Z","iopub.execute_input":"2023-08-10T16:21:24.995069Z","iopub.status.idle":"2023-08-10T16:21:27.076397Z","shell.execute_reply.started":"2023-08-10T16:21:24.995028Z","shell.execute_reply":"2023-08-10T16:21:27.075435Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"def clean_column_name(column_name):\n    cleaned_name = re.sub('[^A-Za-z0-9]+', '_', column_name)\n    return cleaned_name\n\ndef smape(actual, forecast):\n    return 100 * np.mean(2 * np.abs(actual - forecast) / (np.abs(actual) + np.abs(forecast)))","metadata":{"execution":{"iopub.status.busy":"2023-08-10T16:21:27.077775Z","iopub.execute_input":"2023-08-10T16:21:27.078091Z","iopub.status.idle":"2023-08-10T16:21:27.084866Z","shell.execute_reply.started":"2023-08-10T16:21:27.078064Z","shell.execute_reply":"2023-08-10T16:21:27.083768Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def models(train_url,test_url,random_state=42) :\n    # URL of the shared Google Drive file'\n    # Download the CSV file using gdown\n    train_output_path = 'train.csv'  # Output file name\n    test_output_path='test.csv'\n    gdown.download(train_url, train_output_path, quiet=False)\n    gdown.download(test_url, test_output_path, quiet=False)\n    # Read the downloaded CSV file using pandas\n    train = pd.read_csv(train_output_path)\n    test=pd.read_csv(test_output_path)\n\n\n    # Rename the columns in train data\n    train.rename(columns={\n        'lanes:backward': clean_column_name('lanes:backward'),\n        'lanes:forward': clean_column_name('lanes:forward')\n    }, inplace=True)\n\n    # Rename the columns in test data\n    test.rename(columns={\n        'lanes:backward': clean_column_name('lanes:backward'),\n        'lanes:forward': clean_column_name('lanes:forward')\n    }, inplace=True)\n    \n    test_percentage=0.2\n    train_data = pd.DataFrame()\n    test_data = pd.DataFrame()\n\n    unique_series = train[['id_jalan', 'id_titik_mulai', 'id_titik_akhir']].drop_duplicates()\n\n    for idx, series in unique_series.iterrows():\n        series_data = train.loc[(train['id_jalan'] == series['id_jalan']) & \n                                (train['id_titik_mulai'] == series['id_titik_mulai']) & \n                                (train['id_titik_akhir'] == series['id_titik_akhir'])]\n\n        # Split the data consistently\n        train_series_data, test_series_data = train_test_split(series_data, test_size=test_percentage, random_state=random_state)\n\n        train_data = pd.concat([train_data, train_series_data])\n        test_data = pd.concat([test_data, test_series_data])\n    X=train_data.drop(['rerata_kecepatan','lit','waktu_setempat'],axis=1)\n    y=train_data['rerata_kecepatan']\n    test2=test_data.drop(['rerata_kecepatan','lit','waktu_setempat'],axis=1)\n    test_=test.drop(['lit','waktu_setempat','id'],axis=1)\n    \n    hyperparameters = {\n        'bagging_fraction': 0.8755808259764284,\n        'bagging_freq': 7,\n        'colsample_bytree': 0.6986775242324904,\n        'feature_fraction': 0.7030964143192601,\n        'lambda_l1': 9.721190480216267,\n        'lambda_l2': 8.688347081675282e-10,\n        'learning_rate': 0.042325537734418946,\n        'max_depth': 58,\n        'min_child_samples': 20,\n        'min_child_weight': 7.690738102055157,\n        'min_data_in_leaf': 27,\n        'n_estimators': 860,\n        'num_leaves': 122,\n        'reg_alpha': 4.8241807763984715e-06,\n        'reg_lambda': 0.28821417300340907,\n        'subsample': 0.667163499608758,\n        'subsample_freq': 8\n    }\n\n    # Create the LGBMRegressor model\n    model2 = lgb.LGBMRegressor(**hyperparameters,random_state=random_state)\n    model2.fit(X,y)\n    return model2,test_data,test2,test_","metadata":{"execution":{"iopub.status.busy":"2023-08-10T16:21:27.086988Z","iopub.execute_input":"2023-08-10T16:21:27.087429Z","iopub.status.idle":"2023-08-10T16:21:27.104140Z","shell.execute_reply.started":"2023-08-10T16:21:27.087364Z","shell.execute_reply":"2023-08-10T16:21:27.102878Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_url = 'https://drive.google.com/uc?id=1MitHM1sgR31OPCm2V4yTdvgEQVOswlej'\ntest_url='https://drive.google.com/uc?id=1U0zyQsBJVm4XtQsWU2VbJfPOCXrkw7NF'\nmodel_final,test_uji,test_data,test=models(train_url,test_url, random_state=42) #agar dapat nilai sama dengan tim kami,gunakan random state 42,\n\n# 1. Model_final adalah modelnya yang sudah di fit ke data latih\n# 2. test_uji adalah data test hasil splitting data train yang masih memiliki rerata_kecepatan\n# 3. test_data adalah data test hasil splitting data train yang sudah tidak ada rerata_kecepatan (digunakan untuk dipredict)\n# 4. test adalah data test yang digunakan untuk prediksi akhir kompetisi","metadata":{"execution":{"iopub.status.busy":"2023-08-10T16:21:27.108083Z","iopub.execute_input":"2023-08-10T16:21:27.108598Z","iopub.status.idle":"2023-08-10T16:22:46.211868Z","shell.execute_reply.started":"2023-08-10T16:21:27.108553Z","shell.execute_reply":"2023-08-10T16:22:46.210807Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1MitHM1sgR31OPCm2V4yTdvgEQVOswlej\nTo: /kaggle/working/train.csv\n100%|██████████| 104M/104M [00:00<00:00, 246MB/s] \nDownloading...\nFrom: https://drive.google.com/uc?id=1U0zyQsBJVm4XtQsWU2VbJfPOCXrkw7NF\nTo: /kaggle/working/test.csv\n100%|██████████| 32.8M/32.8M [00:00<00:00, 124MB/s] \n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=9.721190480216267, reg_alpha=4.8241807763984715e-06 will be ignored. Current value: lambda_l1=9.721190480216267\n[LightGBM] [Warning] bagging_fraction is set=0.8755808259764284, subsample=0.667163499608758 will be ignored. Current value: bagging_fraction=0.8755808259764284\n[LightGBM] [Warning] feature_fraction is set=0.7030964143192601, colsample_bytree=0.6986775242324904 will be ignored. Current value: feature_fraction=0.7030964143192601\n[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n[LightGBM] [Warning] lambda_l2 is set=8.688347081675282e-10, reg_lambda=0.28821417300340907 will be ignored. Current value: lambda_l2=8.688347081675282e-10\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2023-08-10T16:22:46.213203Z","iopub.execute_input":"2023-08-10T16:22:46.213531Z","iopub.status.idle":"2023-08-10T16:22:46.259342Z","shell.execute_reply.started":"2023-08-10T16:22:46.213501Z","shell.execute_reply":"2023-08-10T16:22:46.258256Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"        id_jalan  id_titik_mulai  id_titik_akhir  busway  cycleway  foot  \\\n46742         19             102             345       0         2     0   \n65557         19             102             345       0         2     0   \n28895         19             102             345       0         2     0   \n378548        19             102             345       0         2     0   \n359718        19             102             345       0         2     0   \n...          ...             ...             ...     ...       ...   ...   \n216817         9             235             358       0         0     0   \n383663         9             235             358       0         0     0   \n22761          9             235             358       0         0     0   \n238612         9             235             358       0         0     0   \n15487          9             235             358       0         0     0   \n\n        highway  lanes  maxspeed  name  ...  hour  weekday  holiday  distance  \\\n46742         2      1         1    18  ...     8        0        1  0.007914   \n65557         2      1         1    18  ...    11        1        1  0.007914   \n28895         2      1         1    18  ...    10        6        1  0.007914   \n378548        2      1         1    18  ...     0        5        1  0.007914   \n359718        2      1         1    18  ...    23        3        1  0.007914   \n...         ...    ...       ...   ...  ...   ...      ...      ...       ...   \n216817        0      0         1    14  ...     0        3        1  0.103721   \n383663        0      0         1    14  ...     6        5        1  0.103721   \n22761         0      0         1    14  ...     3        6        1  0.103721   \n238612        0      0         1    14  ...     7        4        3  0.103721   \n15487         0      0         1    14  ...    19        5        1  0.103721   \n\n        hour_sin      hour_cos   day_sin   day_cos  weekday_sin  weekday_cos  \n46742   0.866025 -5.000000e-01  0.605174  0.796093     0.000000     1.000000  \n65557   0.258819 -9.659258e-01  0.762162  0.647386     0.781831     0.623490  \n28895   0.500000 -8.660254e-01  0.419889  0.907575    -0.781831     0.623490  \n378548  0.000000  1.000000e+00 -0.998533  0.054139    -0.974928    -0.222521  \n359718 -0.258819  9.659258e-01 -0.928977 -0.370138     0.433884    -0.900969  \n...          ...           ...       ...       ...          ...          ...  \n216817  0.000000  1.000000e+00  0.319302 -0.947653     0.433884    -0.900969  \n383663  1.000000  6.123234e-17 -0.998533  0.054139    -0.974928    -0.222521  \n22761   0.707107  7.071068e-01  0.419889  0.907575    -0.781831     0.623490  \n238612  0.965926 -2.588190e-01  0.108119 -0.994138    -0.433884    -0.900969  \n15487  -0.965926  2.588190e-01  0.214970  0.976621    -0.974928    -0.222521  \n\n[80102 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_jalan</th>\n      <th>id_titik_mulai</th>\n      <th>id_titik_akhir</th>\n      <th>busway</th>\n      <th>cycleway</th>\n      <th>foot</th>\n      <th>highway</th>\n      <th>lanes</th>\n      <th>maxspeed</th>\n      <th>name</th>\n      <th>...</th>\n      <th>hour</th>\n      <th>weekday</th>\n      <th>holiday</th>\n      <th>distance</th>\n      <th>hour_sin</th>\n      <th>hour_cos</th>\n      <th>day_sin</th>\n      <th>day_cos</th>\n      <th>weekday_sin</th>\n      <th>weekday_cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>46742</th>\n      <td>19</td>\n      <td>102</td>\n      <td>345</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>18</td>\n      <td>...</td>\n      <td>8</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.007914</td>\n      <td>0.866025</td>\n      <td>-5.000000e-01</td>\n      <td>0.605174</td>\n      <td>0.796093</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>65557</th>\n      <td>19</td>\n      <td>102</td>\n      <td>345</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>18</td>\n      <td>...</td>\n      <td>11</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.007914</td>\n      <td>0.258819</td>\n      <td>-9.659258e-01</td>\n      <td>0.762162</td>\n      <td>0.647386</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n    </tr>\n    <tr>\n      <th>28895</th>\n      <td>19</td>\n      <td>102</td>\n      <td>345</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>18</td>\n      <td>...</td>\n      <td>10</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0.007914</td>\n      <td>0.500000</td>\n      <td>-8.660254e-01</td>\n      <td>0.419889</td>\n      <td>0.907575</td>\n      <td>-0.781831</td>\n      <td>0.623490</td>\n    </tr>\n    <tr>\n      <th>378548</th>\n      <td>19</td>\n      <td>102</td>\n      <td>345</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>18</td>\n      <td>...</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0.007914</td>\n      <td>0.000000</td>\n      <td>1.000000e+00</td>\n      <td>-0.998533</td>\n      <td>0.054139</td>\n      <td>-0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>359718</th>\n      <td>19</td>\n      <td>102</td>\n      <td>345</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>18</td>\n      <td>...</td>\n      <td>23</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.007914</td>\n      <td>-0.258819</td>\n      <td>9.659258e-01</td>\n      <td>-0.928977</td>\n      <td>-0.370138</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>216817</th>\n      <td>9</td>\n      <td>235</td>\n      <td>358</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>14</td>\n      <td>...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.103721</td>\n      <td>0.000000</td>\n      <td>1.000000e+00</td>\n      <td>0.319302</td>\n      <td>-0.947653</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>383663</th>\n      <td>9</td>\n      <td>235</td>\n      <td>358</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>14</td>\n      <td>...</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0.103721</td>\n      <td>1.000000</td>\n      <td>6.123234e-17</td>\n      <td>-0.998533</td>\n      <td>0.054139</td>\n      <td>-0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>22761</th>\n      <td>9</td>\n      <td>235</td>\n      <td>358</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>14</td>\n      <td>...</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0.103721</td>\n      <td>0.707107</td>\n      <td>7.071068e-01</td>\n      <td>0.419889</td>\n      <td>0.907575</td>\n      <td>-0.781831</td>\n      <td>0.623490</td>\n    </tr>\n    <tr>\n      <th>238612</th>\n      <td>9</td>\n      <td>235</td>\n      <td>358</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>14</td>\n      <td>...</td>\n      <td>7</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0.103721</td>\n      <td>0.965926</td>\n      <td>-2.588190e-01</td>\n      <td>0.108119</td>\n      <td>-0.994138</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>15487</th>\n      <td>9</td>\n      <td>235</td>\n      <td>358</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>14</td>\n      <td>...</td>\n      <td>19</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0.103721</td>\n      <td>-0.965926</td>\n      <td>2.588190e-01</td>\n      <td>0.214970</td>\n      <td>0.976621</td>\n      <td>-0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n  </tbody>\n</table>\n<p>80102 rows × 33 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"smape(test_uji.rerata_kecepatan,model_final.predict(test_data))","metadata":{"execution":{"iopub.status.busy":"2023-08-10T16:22:46.260925Z","iopub.execute_input":"2023-08-10T16:22:46.261366Z","iopub.status.idle":"2023-08-10T16:22:49.248607Z","shell.execute_reply.started":"2023-08-10T16:22:46.261325Z","shell.execute_reply":"2023-08-10T16:22:49.247809Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"7.035693335456338"},"metadata":{}}]},{"cell_type":"code","source":"preds=model_final.predict(test)  ##Prediksi Akhir","metadata":{"execution":{"iopub.status.busy":"2023-08-10T16:22:49.249879Z","iopub.execute_input":"2023-08-10T16:22:49.250376Z","iopub.status.idle":"2023-08-10T16:22:53.976868Z","shell.execute_reply.started":"2023-08-10T16:22:49.250348Z","shell.execute_reply":"2023-08-10T16:22:53.975944Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"subs=pd.read_csv(\"/kaggle/input/ristek-datathon-2023/sample_submission.csv\")\nsubs.rerata_kecepatan=preds","metadata":{"execution":{"iopub.status.busy":"2023-08-10T16:22:53.978164Z","iopub.execute_input":"2023-08-10T16:22:53.978671Z","iopub.status.idle":"2023-08-10T16:22:54.041968Z","shell.execute_reply.started":"2023-08-10T16:22:53.978640Z","shell.execute_reply":"2023-08-10T16:22:54.040753Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"subs","metadata":{"execution":{"iopub.status.busy":"2023-08-10T16:22:54.043729Z","iopub.execute_input":"2023-08-10T16:22:54.044072Z","iopub.status.idle":"2023-08-10T16:22:54.057886Z","shell.execute_reply.started":"2023-08-10T16:22:54.044042Z","shell.execute_reply":"2023-08-10T16:22:54.056725Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"            id  rerata_kecepatan\n0            0         42.890395\n1            1         39.394490\n2            2         36.633916\n3            3         43.797419\n4            4         29.922601\n...        ...               ...\n127484  127484         32.130616\n127485  127485         36.339269\n127486  127486         41.980684\n127487  127487         35.365824\n127488  127488         45.269357\n\n[127489 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>rerata_kecepatan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>42.890395</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>39.394490</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>36.633916</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>43.797419</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>29.922601</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>127484</th>\n      <td>127484</td>\n      <td>32.130616</td>\n    </tr>\n    <tr>\n      <th>127485</th>\n      <td>127485</td>\n      <td>36.339269</td>\n    </tr>\n    <tr>\n      <th>127486</th>\n      <td>127486</td>\n      <td>41.980684</td>\n    </tr>\n    <tr>\n      <th>127487</th>\n      <td>127487</td>\n      <td>35.365824</td>\n    </tr>\n    <tr>\n      <th>127488</th>\n      <td>127488</td>\n      <td>45.269357</td>\n    </tr>\n  </tbody>\n</table>\n<p>127489 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"subs.to_csv(\"subs.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T16:23:08.369667Z","iopub.execute_input":"2023-08-10T16:23:08.370053Z","iopub.status.idle":"2023-08-10T16:23:08.890183Z","shell.execute_reply.started":"2023-08-10T16:23:08.370023Z","shell.execute_reply":"2023-08-10T16:23:08.889239Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}